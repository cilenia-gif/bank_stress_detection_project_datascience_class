# Data Sources and Preprocessing

This document explains how the data for this project was obtained, processed, and organized. Due to technical limitations in my development environment (Nuvolos + VS Code), the automated data ingestion pipeline could not access external APIs such as yfinance. As a result, all raw data used in this project was manually downloaded using Google Colab.

The project still includes the original ingestion scripts (`data_utils.py` and `01_data_download_and_etl.ipynb`) to demonstrate how the data download process was intended to work, even though these scripts could not be executed successfully in the Nuvolos environment.

---

## Project Data Structure

The `data/` directory contains two main folders:

1. data/raw/  
   This folder contains the manually downloaded historical stock price data.  
   The dataset was generated in Google Colab and saved as:

   ```bash
   data/raw/sample_prices.csv
   ```

2. data/processed/  
   This folder contains intermediate datasets created during exploratory data analysis and preprocessing. These include cleaned and feature-engineered CSV files generated within the notebook environment.

---

## Reason for Manual Data Downloading

Attempts to download data programmatically within:

- `data_utils.py`
- `01_data_download_and_etl.ipynb`

were unsuccessful because the Nuvolos/VS Code environment was unable to reach the external yfinance API.

To continue the project, the data was manually obtained through Google Colab, where network connectivity and package functionality worked reliably.

Although these scripts are non-functional in this environment, they remain included in the repository for transparency and to show the intended automated pipeline.

---

## Data Download Procedure in Google Colab

The dataset was manually downloaded via a controlled process in Google Colab, which included the following checks and steps.

### 1. Connectivity Test

Ensure that Colab could reach external servers:

```python
# connectivity_test.py (example)
import requests, socket, sys

print("requests installed:", "requests" in sys.modules or True)

try:
    r = requests.get("https://www.google.com", timeout=5)
    print("HTTP OK:", r.status_code)
except Exception as e:
    print("HTTP error:", repr(e))

try:
    socket.create_connection(("8.8.8.8", 53), 3)
    print("Socket OK: can reach 8.8.8.8:53")
except Exception as e:
    print("Socket error:", repr(e))
```

### 2. Verification of yfinance Functionality

Tested downloading a small sample (JPM) to confirm that `yfinance` worked:

```bash
# run in a Colab cell to ensure dependencies
!pip install --quiet yfinance pandas
```

```python
# verify_yfinance.py (example)
import yfinance as yf
import pandas as pd

print("yfinance version:", yf.__version__)

# download a sample ticker
df = yf.download("JPM", period="5d", progress=False, auto_adjust=True)
print("Shape:", df.shape)
print(df.head())
```

### 3. Full Dataset Download and CSV Export

A robust per-ticker loop was used to avoid multi-index issues and to produce a single per-project CSV file:

```python
# full_download.py (example)
import yfinance as yf
import pandas as pd

tickers = ["JPM","BAC","C","WFC","GS","MS","USB","PNC","TFC","CMA","CFG"]
start = "2000-01-01"

df_list = []
for t in tickers:
    try:
        print("Downloading", t)
        hist = yf.Ticker(t).history(start=start, auto_adjust=True)
        if not hist.empty:
            # keep only Close (or rename as needed) and reset index
            s = hist[["Close"]].rename(columns={"Close": t})
            df_list.append(s)
    except Exception as e:
        print("Error for", t, ":", repr(e))

if df_list:
    # combine per-ticker series into a single DataFrame by index (date)
    prices = pd.concat(df_list, axis=1).sort_index()
    out = "data/raw/sample_prices.csv"
    prices.to_csv(out, index_label="Date")
    print("Saved:", out)
```

If using Colab, optionally download the CSV to local machine:

```python
from google.colab import files
files.download("data/raw/sample_prices.csv")
```

---

## Included Datasets

- Folder: data/raw/  
  Files: `sample_prices.csv`  
  Description: Manually downloaded adjusted close prices for selected bank tickers (2000â€“present).

- Folder: data/processed/  
  Files: multiple CSV files  
  Description: Cleaned, transformed, and intermediate datasets used for analysis.

---

## Reproducibility Notes

1. The dataset can be regenerated by running the same Colab notebook cells listed above.  
2. The project does not rely on real-time API calls at runtime; all runtime computations use the stored CSV files.  
3. The original ingestion scripts are included but remain non-functional in the Nuvolos environment due to network restrictions.

---